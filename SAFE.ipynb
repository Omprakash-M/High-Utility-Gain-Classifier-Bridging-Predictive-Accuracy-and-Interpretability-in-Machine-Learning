{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ab0286e-ab08-48a5-af9a-3dfaac9c980a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training on: pimaIndianDiabetes\n",
      "\n",
      " Training on: Heloc\n",
      "\n",
      " Training on: BankMarketingUCI\n",
      "\n",
      " Final Evaluation Summary:\n",
      "\n",
      "           Dataset  Accuracy  F1 Score      AUC  Log Loss  H-measure\n",
      "pimaIndianDiabetes  0.692641  0.422764 0.784774  0.521972   0.329809\n",
      "             Heloc  0.651052  0.673621 0.700655  0.629886   0.147809\n",
      "  BankMarketingUCI  0.887351  0.000000 0.700507  0.318771   0.154448\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "from sklearn.pipeline import Pipeline\n",
    "from SafeTransformer import SafeTransformer\n",
    "import warnings\n",
    "try:\n",
    "    from hmeasure import h_score\n",
    "    hmeasure_available = True\n",
    "except ImportError:\n",
    "    hmeasure_available = False\n",
    "\n",
    "datasets = {\n",
    "    'pimaIndianDiabetes': {\n",
    "        'path': 'datasets/pima indians diabetes.csv',\n",
    "        'target': 'Outcome',\n",
    "        'header': None,\n",
    "        'columns': ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', \n",
    "                    'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
    "    },\n",
    "    'Heloc': {\n",
    "        'path': 'datasets/heloc.csv',\n",
    "        'target': 'RiskPerformance',\n",
    "        'header': 0,\n",
    "        'columns': None\n",
    "    },\n",
    "    'BankMarketingUCI': {\n",
    "        'path': 'bank_marketing.csv',\n",
    "        'target': 'RiskPerformance',  # <- this is the fixed target\n",
    "        'header': 0,\n",
    "        'columns': None\n",
    "    }\n",
    "}\n",
    "results = []\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for name, config in datasets.items():\n",
    "    print(f\"\\n Training on: {name}\")\n",
    "\n",
    "    # Load\n",
    "    df = pd.read_csv(config['path'], header=config['header'])\n",
    "    if config['columns']:\n",
    "        df.columns = config['columns']\n",
    "    y = df[config['target']]\n",
    "    X = df.drop(columns=config['target'])\n",
    "\n",
    "    # Convert target\n",
    "    if y.dtype == 'object':\n",
    "        y = y.map({'yes': 1, 'no': 0, 'Good': 0, 'Bad': 1}).astype(int)\n",
    "\n",
    "    # Dummies\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "    \n",
    "    # Downcast to float32\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, random_state=42, test_size=0.3\n",
    "    )\n",
    "\n",
    "    # Super fast surrogate\n",
    "    surrogate_model = GradientBoostingClassifier(\n",
    "        n_estimators=3,  # minimal\n",
    "        max_depth=1,\n",
    "        learning_rate=0.3,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fast logistic regression\n",
    "    log_model = LogisticRegression(max_iter=50, solver='liblinear')\n",
    "\n",
    "    # Safe transformer - high penalty = few splits\n",
    "    safe_transformer = SafeTransformer(\n",
    "        surrogate_model,\n",
    "        penalty=200,  # fewer splits\n",
    "        pelt_model='l2',\n",
    "        no_changepoint_strategy='median'\n",
    "    )\n",
    "\n",
    "    # Fit pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('safe', safe_transformer),\n",
    "        ('logreg', log_model)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Metrics\n",
    "    results.append({\n",
    "        'Dataset': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'F1 Score': f1_score(y_test, y_pred),\n",
    "        'AUC': roc_auc_score(y_test, y_proba),\n",
    "        'Log Loss': log_loss(y_test, y_proba),\n",
    "        'H-measure': h_score(y_test.to_numpy(), y_proba) if hmeasure_available else \"Not installed\"\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "print(\"\\n Final Evaluation Summary:\\n\")\n",
    "print(pd.DataFrame(results).to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
